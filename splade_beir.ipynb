{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ac4e511-5d44-4c08-a57b-8772b0a3f4ba",
   "metadata": {},
   "source": [
    "# SPLADE: Sparse Lexical and Expansion Model for First Stage Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5133de-c802-4669-ae18-3d99c8d3b197",
   "metadata": {},
   "source": [
    "This notebook gives a minimal example usage of our SPLADE model with beir. \n",
    "\n",
    "We will soon provide the weights and details for the distilled model. Here are the BEIR performance of that model (weights/splade_distil_v2)\n",
    "\n",
    "|      dataset      | NDCG@10 | Recall@100 |\n",
    "|:-----------------:|:-------:|:----------:|\n",
    "|      arguana      |  0.479  |   97.23%   |\n",
    "|   climate-fever   |  0.235  |   52.43%   |\n",
    "|      DBPedia      |  0.435  |   57.52%   |\n",
    "|       fever       |  0.786  |   95.14%   |\n",
    "|        fiqa       |  0.336  |   62.10%   |\n",
    "|      hotpotqa     |  0.684  |   82.03%   |\n",
    "|      nfcorpus     |  0.334  |   27.71%   |\n",
    "|         nq        |  0.521  |   93.05%   |\n",
    "|       quora       |  0.838  |   98.69%   |\n",
    "|      scidocs      |  0.158  |   36.43%   |\n",
    "|      scifact      |  0.693  |   92.03%   |\n",
    "|     trec-covid    |  0.710  |   54.98%   |\n",
    "|  webis-touche2020 |  0.364  |   35.39%   |\n",
    "| Average zero shot |  0.506  |   66.89%   |\n",
    "\n",
    "## Versions:\n",
    "\n",
    "* Transformers: 4.2.2\n",
    "* PyTorch: 1.7.0\n",
    "* Beir: 0.1.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03e94b11-ee3c-454d-8858-15b8615a7017",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Splade, BEIRSpladeModel\n",
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d60f22ed-5edb-4af8-8323-15bb604ff230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the dir for trained weights \n",
    "model_type_or_dir = \"weights/splade_distil_v2\"\n",
    "# model_type_or_dir = \"weights/flops_best\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3034300e-fb01-4049-8f3c-ede83ec57f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading model and tokenizer\n",
    "\n",
    "model = Splade(model_type_or_dir)\n",
    "model.eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_type_or_dir)\n",
    "beir_splade = BEIRSpladeModel(model,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7af12fd-34da-4608-a06c-d9b8c8d54606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "from beir import util, LoggingHandler\n",
    "\n",
    "dataset = \"nfcorpus\"\n",
    "\n",
    "url = \"https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/{}.zip\".format(dataset)\n",
    "out_dir = \"dataset\".format(dataset)\n",
    "data_path = util.download_and_unzip(url, out_dir)\n",
    "\n",
    "\n",
    "#### Provide the data path where nfcorpus has been downloaded and unzipped to the data loader\n",
    "# data folder would contain these files: \n",
    "# (1) nfcorpus/corpus.jsonl  (format: jsonlines)\n",
    "# (2) nfcorpus/queries.jsonl (format: jsonlines)\n",
    "# (3) nfcorpus/qrels/test.tsv (format: tsv (\"\\t\"))\n",
    "\n",
    "corpus, queries, qrels = GenericDataLoader(data_folder=data_path).load(split=\"test\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a194ec2-c69d-4848-8ca4-80fed739911a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4af45b9c73a4a629acc1616c9362e21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb89a16b9d549eabfe9bdca058b09b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NDCG@10': 0.33409, 'Recall@100': 0.27705, 'R_cap@100': 0.29269}\n"
     ]
    }
   ],
   "source": [
    "from beir.retrieval.search.dense import DenseRetrievalExactSearch as DRES\n",
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "\n",
    "dres = DRES(beir_splade)\n",
    "\n",
    "retriever = EvaluateRetrieval(dres, score_function=\"dot\") # or \"dot\" for dot-product\n",
    "results = retriever.retrieve(corpus, queries)\n",
    "ndcg, map_, recall, p = EvaluateRetrieval.evaluate(qrels, results, [1,10,100,1000]) \n",
    "results2 = EvaluateRetrieval.evaluate_custom(qrels, results, [1,10,100,1000], metric = \"r_cap\")   \n",
    "res = {\n",
    "    \"NDCG@10\":ndcg[\"NDCG@10\"],\n",
    "    \"Recall@100\": recall[\"Recall@100\"],\n",
    "    \"R_cap@100\": results2[\"R_cap@100\"]\n",
    "}\n",
    "print(res,flush=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:beir-env]",
   "language": "python",
   "name": "conda-env-beir-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
